{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Linear regression, is a **linear** regression model. It has been around for quite some time and it is still used heavily today. It doesn't achieve state of art performance, but it helps us answer some questions that other models can't answer. Some of those questions are: \n",
    "\n",
    "1) Are the independent variables related to the dependent variable? \n",
    "\n",
    "2) How strongly are they related? \n",
    "\n",
    "3) How certain are we that the independent variables are related to the dependent variable?\n",
    "\n",
    "4) Is the relationship between independent variables and dependent variable linear?\n",
    "\n",
    "5) Is there synergy among independent variables?\n",
    "\n",
    "## Formula \n",
    "\n",
    "Linear regression models, belong to the family of **parametric** methods. The formula of linear regression is:\n",
    "\n",
    "$$\\displaystyle \\mathbf {y} =X{\\boldsymbol {\\beta }}+{\\boldsymbol {\\varepsilon }}$$\n",
    "\n",
    "$$\\displaystyle \\mathbf {y} ={\\begin{pmatrix}y_{1}\\\\y_{2}\\\\\\vdots \\\\y_{n}\\end{pmatrix}},\\quad $$ $$\\quad \n",
    "\\displaystyle X={\\begin{pmatrix}\\mathbf {x} _{1}^{\\top }\\\\\\mathbf {x} _{2}^{\\top }\\\\\\vdots \\\\\\mathbf {x} _{n}^{\\top }\\end{pmatrix}}={\\begin{pmatrix}1&x_{11}&\\cdots &x_{1p}\\\\1&x_{21}&\\cdots &x_{2p}\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\1&x_{n1}&\\cdots &x_{np}\\end{pmatrix}},$$ \n",
    "$$\\displaystyle {\\boldsymbol {\\beta }}={\\begin{pmatrix}\\beta _{0}\\\\\\beta _{1}\\\\\\beta _{2}\\\\\\vdots \\\\\\beta _{p}\\end{pmatrix}},\\quad {\\boldsymbol {\\varepsilon }}={\\begin{pmatrix}\\varepsilon _{1}\\\\\\varepsilon _{2}\\\\\\vdots \\\\\\varepsilon _{n}\\end{pmatrix}}.$$\n",
    "\n",
    "Where: $\\mathbf {y}$ are the dependent variable , $\\mathbf {X}$ is the dependent variables, $\\displaystyle {\\boldsymbol {\\beta }}$ are the training parameters, and $\\displaystyle {\\boldsymbol {\\varepsilon }}$ is the error term. \n",
    "\n",
    "## Assumptions \n",
    "\n",
    "1) Weak exogeneity - independent variables are not wrongly measured (unrealistic assumption at most cases)\n",
    "\n",
    "2) Linearity - the dependent variable is a linear combination of the independent variables \n",
    "\n",
    "3) Homoscedasticity - constant variance, meaning constant error term\n",
    "\n",
    "4) Independence of errors - errors are not correlated (white noise)\n",
    "\n",
    "5) Lack of perfect multicollinearity - independence among independent variables\n",
    "\n",
    "\n",
    "# Implementation\n",
    "\n",
    "In this section, we will apply the various models of linear regression.\n",
    "\n",
    "## Simple Linear Regression\n",
    "\n",
    "It is a linear regression with a single independent variable, therefore its formula should be: \n",
    "\n",
    "$$Y = \\beta_{0} + \\beta_{1} x_{1} + \\varepsilon$$\n",
    "\n",
    "Where $\\beta_{0}$ and $\\beta_{1}$ are two unknown constants that represent the intercept and slope terms (aka model parameters/coefficients) in the linear model. Once the model is trained from the data, and we have produced the estimates $\\hat{\\beta_{0}}$ and $\\hat{\\beta_{1}}$ we will be able to predict the future values of $Y$ by computing: $$ \\hat{y} = \\hat{\\beta_{0}} + \\hat{\\beta_{1}} x$$\n",
    "\n",
    "\n",
    "We can implement the simple linear regression using the built-in 'Boston' data set from the sklearn module.\n",
    "\n",
    "As dependent variable (target) we will use the $MEDV$ (median value of owner-occupied homes in 1000$) and as independent variable the $RM$(average numbers of rooms per dwelling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.593761</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.596783</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.647423</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels import api\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import datasets \n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "data = datasets.load_boston()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "target = pd.DataFrame(data.target, columns=[\"MEDV\"])\n",
    "\n",
    "# Let's check out the data frame\n",
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MEDV\n",
       "count  506.000000\n",
       "mean    22.532806\n",
       "std      9.197104\n",
       "min      5.000000\n",
       "25%     17.025000\n",
       "50%     21.200000\n",
       "75%     25.000000\n",
       "max     50.000000"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the target variables \n",
    "\n",
    "target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['RM']]\n",
    "y = target['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training \n",
    "\n",
    "A question someone could have is, but how are those parameters got trained?\n",
    "\n",
    "We used the least squared method. This method aims to modify the parameters so that the sum of residuals is minimized.\n",
    "\n",
    "But how is the sum of residuals is defined?\n",
    "\n",
    "$$RSS = \\sum_{i=1}^{n}e_{i}^{2}$$\n",
    "\n",
    "where $e_{i} = y_{i}-\\hat{y_{i}} = y_{i} - \\hat{\\beta_{0}}- \\hat{\\beta_{1}} x_{i}$\n",
    "\n",
    "For a simple linear regression, the parameters to minimize the RSS are calculated as following: \n",
    "\n",
    "$$\\hat{\\beta_{1}} = \\dfrac{\\sum_{i = 1}^{n}(x_{i} - \\bar{x})(y_{i}-\\bar{y})}{\\sum_{i = 1}^{n}(x_{i} - \\bar{x})^{2}}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\hat{\\beta_{0}} = \\bar{y} - \\hat{\\beta_{1}}\\bar{x}$$\n",
    "\n",
    "where $\\bar{y} = \\sum_{i = 1}^{n}y_{i}$ and $\\bar{x} = \\sum_{i = 1}^{n}x_{i}$ are the sample means. \n",
    "\n",
    "The standard error of an estimator reflects how it varies under repeated sampling.\n",
    "\n",
    "$ SE(\\hat{\\beta_{1}})^{2} = \\dfrac{\\sigma^{2}}{\\sum_{i = 1}^{n}(x_{i} - \\bar{x})^{2}}$, $ SE(\\hat{\\beta_{0}})^{2} = \\sigma^{2}[\\dfrac{1}{n}+\\dfrac{\\bar{x}^{2}}{\\sum_{i = 1}^{n}(x_{i} - \\bar{x})^{2}}]$, where $\\sigma^{2} = Var(\\varepsilon)$.\n",
    "\n",
    "These standard errors can be used to compute confidence intervals. A 95% **confidence interval** is defined as a range of values such that with 95% probability, the range will contain the true unknown value of the parameter. It has the form: \n",
    "\n",
    "$$\\hat{\\beta_{1}} \\pm 2 SE(\\hat{\\beta_{1}})$$\n",
    "\n",
    "\n",
    "Standard errors can also be used to perform **hypothesis tests** on the coefficients. The most common hypothesis test involves testing the null hypothesis of:\n",
    "H 0 : There is no relationship between X and Y versus the alternative hypothesis\n",
    "H A : There is some relationship between X and Y .\n",
    "\n",
    "Mathematically, this corresponds to testing\n",
    "$$H 0 : \\beta_{1} = 0$$\n",
    "\n",
    "versus\n",
    "$$H A : \\beta_{1} \\neq 0$$\n",
    "\n",
    "since if $\\beta_{1} = 0$ then the model reduces to $Y = \\beta_{0} + \\varepsilon, and X is not associated with Y.\n",
    "\n",
    "To test the null hypothesis, we compute a t-statistic, given by:\n",
    "\n",
    "$$t =  \\dfrac{\\hat{\\beta_{1}}-0}{SE(\\hat{\\beta_{1}})}$$\n",
    "\n",
    "This will have a t-distribution with n − 2 degrees of freedom, assuming $\\beta_{1} = 0$.\n",
    "\n",
    "Using statistical software, it is easy to compute the probability of observing any value equal to |t| or larger. We\n",
    "call this probability the p-value.\n",
    "\n",
    "### Model Performance\n",
    "\n",
    "In order to measure the performance of the predictive model, we can use RSE (Residual Standard Error), R-squared, F-statistic. \n",
    "\n",
    "The RSE is calculated as following: \n",
    "\n",
    "$$\\sqrt{\\dfrac{1}{n-2}RSS} = \\sqrt{\\dfrac{\\sum_{i=1}^{n}e_{i}^{2}}{n-2}} = \\sqrt{\\dfrac{\\sum_{i=1}^{n}(y_{i}-\\hat{y_{i}})^{2}}{n-2}}$$\n",
    "\n",
    "The R-squared is calculated as following: \n",
    "\n",
    "$$R^{2} = \\dfrac{TSS - RSS}{TSS} = 1 - \\dfrac{RSS}{TSS}$$\n",
    "\n",
    "Where TSS is the total sum of squares that is calculated as $\\sum_{i}(y_{i}-\\bar{y})^{2}$\n",
    "\n",
    "The F-statistic is calculated as following: \n",
    "\n",
    "$$F = \\dfrac{\\dfrac{TSS-RSS}{p}}{\\dfrac{RSS}{n - p - 1}}$$\n",
    "\n",
    "Where p is the number of independent variables and n the number of samples. \n",
    "\n",
    "F-statistic indicates whether there is a relationship between the predictors and the target. If F-statistic is close to 1, there is no relationship.\n",
    "\n",
    "Using the p-values we can see which are the important variables. But what do we do if not all variables are not significant? Well, remove them! This process is called variable selection. We can't go over all the possible combinations because there are $2^{p}$ combinations. I will not go through great detail on this task, but only through the most basic approaches. \n",
    "\n",
    "* **Forward selection**: We begin with intercept, then we add the variable that leads to the lowest RSS. This process continues till some stoping rule is satisfied.\n",
    "\n",
    "* **Backward selection**: We begin with all the variables, then we remove the variable with the highest p-value. This process continues till some stoping rule is satisfied.\n",
    "\n",
    "* **Mixed selection**: We start with no variables in the model, and as with forward selection, we add the variable that provides the best fit. However if one variable's p-value is above a certain threshold we remove it. We keep on doing those steps up until all the model's variables have low p-value and the variables outside the model have high p-values.\n",
    "\n",
    "Some other notable ways to measure the model's performance are: \n",
    "\n",
    "* **Adjusted R-Squared**: Adjusted $R^{2}$ also indicates how well terms fit a curve or line, but adjusts for the number of terms in a model.$1-[\\dfrac{(1-R^{2})(n-1)}{n-k-1}]$\n",
    "\n",
    "* **MSE**: The mean squared error, $\\dfrac{\\sum_{i}^{n}(y_{i}-f_{i})^{2}}{n}$\n",
    "\n",
    "* **RMSE**: The root mean squared error, $\\sqrt{\\dfrac{\\sum_{i}^{n}(y_{i}-f_{i})^{2}}{n}}$\n",
    "\n",
    "* **AIC**: an estimate of the relative information lost when a given model is used to represent the process that generated the data. (In doing so, it deals with the trade-off between the goodness of fit of the model and the simplicity of the model.) The model with the lowest AIC is preferred.\n",
    "\n",
    "* **BIC**:  It is closely related to the Akaike information criterion (AIC), but with a different penalty for the number of parameters. The model with the lowest BIC is preferred.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "But before we fit the model, let's visualize the relationship between the two variables so that we know what to expect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngVJK5TlNBEoplec0ESilVJ77f5zT4c1hB75yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f52c39326a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y, c=\"black\", alpha=0.5)\n",
    "plt.xlabel(\"RM\")\n",
    "plt.ylabel(\"MEDV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should expect to have a positive slope term and a negative intercept. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   MEDV   R-squared:                       0.484\n",
      "Model:                            OLS   Adj. R-squared:                  0.483\n",
      "Method:                 Least Squares   F-statistic:                     471.8\n",
      "Date:                Sun, 28 Jan 2018   Prob (F-statistic):           2.49e-74\n",
      "Time:                        17:09:22   Log-Likelihood:                -1673.1\n",
      "No. Observations:                 506   AIC:                             3350.\n",
      "Df Residuals:                     504   BIC:                             3359.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -34.6706      2.650    -13.084      0.000     -39.877     -29.465\n",
      "RM             9.1021      0.419     21.722      0.000       8.279       9.925\n",
      "==============================================================================\n",
      "Omnibus:                      102.585   Durbin-Watson:                   0.684\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              612.449\n",
      "Skew:                           0.726   Prob(JB):                    1.02e-133\n",
      "Kurtosis:                       8.190   Cond. No.                         58.4\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "df_c = pd.concat((df, target['MEDV']), axis = 1)\n",
    "mod = smf.ols(formula='MEDV ~ RM', data=df_c)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way of doing a simple linear regression is : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   471.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 28 Jan 2018</td> <th>  Prob (F-statistic):</th> <td>2.49e-74</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:09:30</td>     <th>  Log-Likelihood:    </th> <td> -1673.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3350.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   504</td>      <th>  BIC:               </th> <td>   3359.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  -34.6706</td> <td>    2.650</td> <td>  -13.084</td> <td> 0.000</td> <td>  -39.877</td> <td>  -29.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>    <td>    9.1021</td> <td>    0.419</td> <td>   21.722</td> <td> 0.000</td> <td>    8.279</td> <td>    9.925</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>102.585</td> <th>  Durbin-Watson:     </th> <td>   0.684</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 612.449</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.726</td>  <th>  Prob(JB):          </th> <td>1.02e-133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.190</td>  <th>  Cond. No.          </th> <td>    58.4</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   MEDV   R-squared:                       0.484\n",
       "Model:                            OLS   Adj. R-squared:                  0.483\n",
       "Method:                 Least Squares   F-statistic:                     471.8\n",
       "Date:                Sun, 28 Jan 2018   Prob (F-statistic):           2.49e-74\n",
       "Time:                        17:09:30   Log-Likelihood:                -1673.1\n",
       "No. Observations:                 506   AIC:                             3350.\n",
       "Df Residuals:                     504   BIC:                             3359.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -34.6706      2.650    -13.084      0.000     -39.877     -29.465\n",
       "RM             9.1021      0.419     21.722      0.000       8.279       9.925\n",
       "==============================================================================\n",
       "Omnibus:                      102.585   Durbin-Watson:                   0.684\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              612.449\n",
       "Skew:                           0.726   Prob(JB):                    1.02e-133\n",
       "Kurtosis:                       8.190   Cond. No.                         58.4\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = api.add_constant(x)\n",
    "model = api.OLS(y, x).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics\n",
    "\n",
    "We will go through the important measures of the summary. The first thing I look at when I am retrieving the summary, is the R-squared so that I can see how well the model explains the variation at the data. In the particular case, R-squared is really low so we should totally work on our model. Another important measure to look at are the P values, it seems that they are both significant (less than 5%). Now, once we know if the model works nice or not, let's interprete the relationship between the variables. The slope term, is $9.102$ which means, that if we increase the value of $RM$ by one, the variable $MDEV$ should increase by $9.102$.\n",
    "\n",
    "Diagnostics are cool, but let's see the line that we have created!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niUAppeLc/wMrSUUMzLtyfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f52c09b4a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_hat = model.predict(x)\n",
    "plt.scatter(x[\"RM\"], y, c=\"black\", alpha=0.5)\n",
    "plt.plot(x[\"RM\"], y_hat)\n",
    "plt.xlabel(\"RM\")\n",
    "plt.ylabel(\"MEDV\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also conduct linear regression using $sklearn$, but it is not recommended because the diagnostics are not as informative. \n",
    "\n",
    "Let's fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['RM']]\n",
    "y = target['MEDV']\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned before, $sklearn's$ diagnostics are a bit poor, and all we can see are the intercept, coefficient (slope term) and the R-squared. This is really not enough because we are don't know how important every variable is for the determination of the model. However, it can be a good indicator if we performed the analysis correctly before, and it seems like we did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.10210898])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-34.670620776438568"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48352545599133429"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "In many cases, simple linear regression is just too simple to be able to predict the target variable because it is influenced by more than one predictors. Let's try to predict $MEDV$ using $RM$ and $LSTAT$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   MEDV   R-squared:                       0.639\n",
      "Model:                            OLS   Adj. R-squared:                  0.637\n",
      "Method:                 Least Squares   F-statistic:                     444.3\n",
      "Date:                Sun, 28 Jan 2018   Prob (F-statistic):          7.01e-112\n",
      "Time:                        17:11:18   Log-Likelihood:                -1582.8\n",
      "No. Observations:                 506   AIC:                             3172.\n",
      "Df Residuals:                     503   BIC:                             3184.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.3583      3.173     -0.428      0.669      -7.592       4.875\n",
      "RM             5.0948      0.444     11.463      0.000       4.222       5.968\n",
      "LSTAT         -0.6424      0.044    -14.689      0.000      -0.728      -0.556\n",
      "==============================================================================\n",
      "Omnibus:                      145.712   Durbin-Watson:                   0.834\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              457.690\n",
      "Skew:                           1.343   Prob(JB):                    4.11e-100\n",
      "Kurtosis:                       6.807   Cond. No.                         202.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "df_c = pd.concat((df, target['MEDV']), axis = 1)\n",
    "mod = smf.ols(formula='MEDV ~ RM + LSTAT', data=df_c)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['RM', 'LSTAT']]\n",
    "y = target['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.639</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.637</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   444.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 28 Jan 2018</td> <th>  Prob (F-statistic):</th> <td>7.01e-112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:11:22</td>     <th>  Log-Likelihood:    </th> <td> -1582.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3172.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   503</td>      <th>  BIC:               </th> <td>   3184.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -1.3583</td> <td>    3.173</td> <td>   -0.428</td> <td> 0.669</td> <td>   -7.592</td> <td>    4.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>    <td>    5.0948</td> <td>    0.444</td> <td>   11.463</td> <td> 0.000</td> <td>    4.222</td> <td>    5.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th> <td>   -0.6424</td> <td>    0.044</td> <td>  -14.689</td> <td> 0.000</td> <td>   -0.728</td> <td>   -0.556</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>145.712</td> <th>  Durbin-Watson:     </th> <td>   0.834</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 457.690</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.343</td>  <th>  Prob(JB):          </th> <td>4.11e-100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.807</td>  <th>  Cond. No.          </th> <td>    202.</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   MEDV   R-squared:                       0.639\n",
       "Model:                            OLS   Adj. R-squared:                  0.637\n",
       "Method:                 Least Squares   F-statistic:                     444.3\n",
       "Date:                Sun, 28 Jan 2018   Prob (F-statistic):          7.01e-112\n",
       "Time:                        17:11:22   Log-Likelihood:                -1582.8\n",
       "No. Observations:                 506   AIC:                             3172.\n",
       "Df Residuals:                     503   BIC:                             3184.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -1.3583      3.173     -0.428      0.669      -7.592       4.875\n",
       "RM             5.0948      0.444     11.463      0.000       4.222       5.968\n",
       "LSTAT         -0.6424      0.044    -14.689      0.000      -0.728      -0.556\n",
       "==============================================================================\n",
       "Omnibus:                      145.712   Durbin-Watson:                   0.834\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              457.690\n",
       "Skew:                           1.343   Prob(JB):                    4.11e-100\n",
       "Kurtosis:                       6.807   Cond. No.                         202.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the model fit!\n",
    "x = api.add_constant(x)\n",
    "model = api.OLS(y, x).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the slope terms are significant while the constant one is not. Moreover, notice that the R-squared is increased as long as the Adjusted R-squared!\n",
    "\n",
    "Let's go ahead now and conduct the forward selection method to retrieve the best model possible. Take into consideration that when we want to have the impactful variables into our model, we focus at **Adjusted R-squared**.\n",
    "\n",
    "At the $statsmodel$ module, there is no such a build in function so we should build it ourselves! The function didn't come out of my head, but it is a modification of this [post](https://planspace.org/20150423-forward_selection_with_statsmodels/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def forward_selected(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   MEDV   R-squared:                       0.741\n",
      "Model:                            OLS   Adj. R-squared:                  0.735\n",
      "Method:                 Least Squares   F-statistic:                     128.2\n",
      "Date:                Sun, 28 Jan 2018   Prob (F-statistic):          5.74e-137\n",
      "Time:                        17:11:34   Log-Likelihood:                -1498.9\n",
      "No. Observations:                 506   AIC:                             3022.\n",
      "Df Residuals:                     494   BIC:                             3073.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     36.3694      5.069      7.176      0.000      26.411      46.328\n",
      "LSTAT         -0.5232      0.047    -11.037      0.000      -0.616      -0.430\n",
      "RM             3.7966      0.406      9.343      0.000       2.998       4.595\n",
      "PTRATIO       -0.9471      0.129     -7.337      0.000      -1.201      -0.693\n",
      "DIS           -1.4934      0.186     -8.039      0.000      -1.858      -1.128\n",
      "NOX          -17.3956      3.536     -4.920      0.000     -24.343     -10.448\n",
      "CHAS           2.7212      0.854      3.185      0.002       1.043       4.400\n",
      "B              0.0094      0.003      3.508      0.000       0.004       0.015\n",
      "ZN             0.0458      0.014      3.387      0.001       0.019       0.072\n",
      "CRIM          -0.1076      0.033     -3.296      0.001      -0.172      -0.043\n",
      "RAD            0.2991      0.063      4.719      0.000       0.175       0.424\n",
      "TAX           -0.0118      0.003     -3.488      0.001      -0.018      -0.005\n",
      "==============================================================================\n",
      "Omnibus:                      178.444   Durbin-Watson:                   1.078\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              786.944\n",
      "Skew:                           1.524   Prob(JB):                    1.31e-171\n",
      "Kurtosis:                       8.295   Cond. No.                     1.47e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.47e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Let's calculate the time that it takes to run\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "df_c = pd.concat([df.reset_index(drop=True), y], axis=1)\n",
    "\n",
    "model = forward_selected(df_c, 'MEDV')\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions of the Linear Model\n",
    "\n",
    "While linear regression models are good, but they make some strong assumptions that at real life they are violated.\n",
    "\n",
    "The linear assumption states that the change in the response $Y$ due to a one-unit change in $X_{j}$ is constant, regardless of the value of $X_{j}$.\n",
    "\n",
    "\n",
    "### Removing the Additive Assumption\n",
    "\n",
    "Consider the standard linear regression model with two variables,\n",
    "\n",
    "$$Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\epsilon$$\n",
    "\n",
    "According to this model, if we increase $X_{1}$ by one unit, then $Y$ will increase by an average of $\\beta_{1}$ units. Notice that the presence of $X_{2}$ does not alter this statement—that is, regardless of the value of $X_2$ , a one-unit increase in $X_1$ will lead to a $\\beta_{1}$-unit increase in $Y$.\n",
    "\n",
    "One way of extending this model to allow for interaction effects is to include a third predictor, called an interaction term, which is constructed by computing the product of $X_{1}$ and $X_{2}$ . This results in the model\n",
    "$$Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{1}X_{2} + \\epsilon$$\n",
    "\n",
    "How does inclusion of this interaction term relax the additive assumption?\n",
    "\n",
    "$$Y = \\beta_{0} +(\\beta_{1}+ \\beta_{3}X_{2})X_{1} + \\beta_{2}X_{2}  + \\epsilon$$\n",
    "$$ = \\beta_{0} +\\tilde{\\beta_{1}}X_{1} + \\beta_{2}X_{2}  + \\epsilon$$\n",
    "\n",
    "Let's try an make an interaction between $LSTAT$ and $RM$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.740</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.739</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   476.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 28 Jan 2018</td> <th>  Prob (F-statistic):</th> <td>1.75e-146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:53:28</td>     <th>  Log-Likelihood:    </th> <td> -1499.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3006.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   502</td>      <th>  BIC:               </th> <td>   3023.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -29.1245</td> <td>    3.342</td> <td>   -8.713</td> <td> 0.000</td> <td>  -35.692</td> <td>  -22.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>     <td>    2.1940</td> <td>    0.206</td> <td>   10.666</td> <td> 0.000</td> <td>    1.790</td> <td>    2.598</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>        <td>    9.7013</td> <td>    0.500</td> <td>   19.393</td> <td> 0.000</td> <td>    8.718</td> <td>   10.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT:RM</th>  <td>   -0.4849</td> <td>    0.035</td> <td>  -14.018</td> <td> 0.000</td> <td>   -0.553</td> <td>   -0.417</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>223.968</td> <th>  Durbin-Watson:     </th> <td>   0.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2182.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.666</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>12.613</td>  <th>  Cond. No.          </th> <td>1.41e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   MEDV   R-squared:                       0.740\n",
       "Model:                            OLS   Adj. R-squared:                  0.739\n",
       "Method:                 Least Squares   F-statistic:                     476.9\n",
       "Date:                Sun, 28 Jan 2018   Prob (F-statistic):          1.75e-146\n",
       "Time:                        17:53:28   Log-Likelihood:                -1499.2\n",
       "No. Observations:                 506   AIC:                             3006.\n",
       "Df Residuals:                     502   BIC:                             3023.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -29.1245      3.342     -8.713      0.000     -35.692     -22.558\n",
       "LSTAT          2.1940      0.206     10.666      0.000       1.790       2.598\n",
       "RM             9.7013      0.500     19.393      0.000       8.718      10.684\n",
       "LSTAT:RM      -0.4849      0.035    -14.018      0.000      -0.553      -0.417\n",
       "==============================================================================\n",
       "Omnibus:                      223.968   Durbin-Watson:                   0.971\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2182.462\n",
       "Skew:                           1.666   Prob(JB):                         0.00\n",
       "Kurtosis:                      12.613   Cond. No.                     1.41e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.41e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_interaction = smf.ols(formula='MEDV ~ LSTAT * RM ', data=df_c).fit()\n",
    "model_interaction.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear Relationships\n",
    "\n",
    "Another assumption that it is usually not true is that the relationship between predictors and response is linear. The solution to this problem is **polynomial regression**.\n",
    "\n",
    "Let's assume that we have two predictors, a possible formula of the polynomial regression could be: \n",
    "\n",
    "$$Y = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2} X_{2} + \\beta_{3} X_{2}^{2} $$\n",
    "\n",
    "Let's try to predict $MEDV$ and $LSTAT$ and $RM$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>MEDV</td>       <th>  R-squared:         </th> <td>   0.703</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.701</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   396.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 28 Jan 2018</td> <th>  Prob (F-statistic):</th> <td>6.50e-132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:03:10</td>     <th>  Log-Likelihood:    </th> <td> -1533.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3074.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   502</td>      <th>  BIC:               </th> <td>   3091.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>   11.6896</td> <td>    3.138</td> <td>    3.725</td> <td> 0.000</td> <td>    5.524</td> <td>   17.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>           <td>   -1.8486</td> <td>    0.122</td> <td>  -15.136</td> <td> 0.000</td> <td>   -2.089</td> <td>   -1.609</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>              <td>    4.2273</td> <td>    0.412</td> <td>   10.267</td> <td> 0.000</td> <td>    3.418</td> <td>    5.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(LSTAT ** 2.0)</th> <td>    0.0363</td> <td>    0.003</td> <td>   10.443</td> <td> 0.000</td> <td>    0.030</td> <td>    0.043</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>123.119</td> <th>  Durbin-Watson:     </th> <td>   0.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 411.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.105</td>  <th>  Prob(JB):          </th> <td>4.15e-90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.826</td>  <th>  Cond. No.          </th> <td>4.49e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   MEDV   R-squared:                       0.703\n",
       "Model:                            OLS   Adj. R-squared:                  0.701\n",
       "Method:                 Least Squares   F-statistic:                     396.2\n",
       "Date:                Sun, 28 Jan 2018   Prob (F-statistic):          6.50e-132\n",
       "Time:                        18:03:10   Log-Likelihood:                -1533.0\n",
       "No. Observations:                 506   AIC:                             3074.\n",
       "Df Residuals:                     502   BIC:                             3091.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept          11.6896      3.138      3.725      0.000       5.524      17.855\n",
       "LSTAT              -1.8486      0.122    -15.136      0.000      -2.089      -1.609\n",
       "RM                  4.2273      0.412     10.267      0.000       3.418       5.036\n",
       "I(LSTAT ** 2.0)     0.0363      0.003     10.443      0.000       0.030       0.043\n",
       "==============================================================================\n",
       "Omnibus:                      123.119   Durbin-Watson:                   0.848\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              411.618\n",
       "Skew:                           1.105   Prob(JB):                     4.15e-90\n",
       "Kurtosis:                       6.826   Cond. No.                     4.49e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.49e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_polynomial = smf.ols(formula='MEDV ~ LSTAT + RM + I(LSTAT ** 2.0)', data=df_c).fit()\n",
    "model_polynomial.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Problems\n",
    "\n",
    "Linear regression is good at some aspects, but it is not really good at others! \n",
    "\n",
    "### 1. Non-linearity of the Data\n",
    "\n",
    "In this case, the performance of the model will be poor. You can diagnose a non-linearity out of the residual plots. If you see a pattern into that plot, then there is a pattern that a linear model cannot capture. \n",
    "\n",
    "### 2. Correlation of error terms\n",
    "\n",
    "In those cases, we may have an unwarranted sense of confidence in our model. Such correlations frequently occur in the context of time series data. \n",
    "\n",
    "### 3. Non-constant Variance of Error Terms\n",
    "\n",
    "It is often the case that the variances of the error terms are\n",
    "non-constant. One can identify non-constant variances in the errors, or heteroscedasticity, from the presence of a funnel shape in the residual plot. \n",
    "\n",
    "\n",
    "When faced with this problem, one possible solution is to transform the response $Y$ using a concave function such as $\\log Y$ or $\\sqrt{Y}$ . Such a transformation results in a greater amount of shrinkage of the larger responses, leading to a reduction in heteroscedasticity.\n",
    "\n",
    "### 4. Outliers\n",
    "\n",
    "An outlier is a point for which y i is far from the value predicted by the model. It is typical for an outlier that does not have an unusual\n",
    "predictor value to have little effect on the least squares fit.  Residual plots can be used to identify outliers. \n",
    "\n",
    "### 5. High Leverage Points\n",
    "\n",
    "This is the exact opposite of the outliers case. This problem occurs when the predictors have abnormal values. \n",
    "\n",
    "In a simple linear regression, high leverage observations are fairly easy to identify, since we can simply look for observations for which the predictor value is outside of the normal range of the observations. This is not the case for multivariate linear regression. \n",
    "\n",
    "In order to quantify an observation’s leverage, we compute the leverage\n",
    "statistic. A large value of this statistic indicates an observation with high leverage.\n",
    "\n",
    "$$h_{i} = \\dfrac{1}{n} + \\dfrac{(x_{i} - \\bar{x})^{2}}{\\sum_{i'=1}^{n}(x_{i'} - \\bar{x})^{2}} $$ \n",
    "\n",
    "It is clear from this equation that $h_{i}$ increases with the distance of $x_{i}$ from $\\bar{x}$. \n",
    "\n",
    "There is a simple extension of $h_{i}$ to the case of multiple predictors, though we do not provide the formula here. The leverage statistic $h_{i}$ is always between $\\dfrac{1}{n}$ and the average leverage for all the observations is always equal to $\\dfrac{p + 1}{n}$. So if a given observation has a leverage statistic that greatly exceeds $\\dfrac{p+ 1}{n}$, then we may suspect that the corresponding\n",
    "point has high leverage.\n",
    "\n",
    "### 6. Collinearity \n",
    "\n",
    "Collinearity refers to the situation in which two or more predictor variables collinearity are closely related to one another. \n",
    "\n",
    "Since collinearity reduces the accuracy of the estimates of the regression coefficients, it causes the standard error for $\\hat{\\beta_{j}}$ to grow. Recall that the t-statistic for each predictor is calculated by dividing $\\hat{\\beta_{j}}$ by its standard\n",
    "error. Consequently, collinearity results in a decline in the t-statistic. As a result, in the presence of collinearity, we may fail to reject $H 0 : \\beta_{j} = 0$. This means that the power of the hypothesis test—the probability of correctly detecting a non-zero coefficient—is reduced by collinearity.\n",
    "\n",
    "Instead of inspecting the correlation matrix, a better way to assess multi-collinearity is to compute the variance inflation factor (VIF). The VIF is the ratio of the variance of $\\hat{\\beta_{j}}$ when fitting the full model divided by the variance of $\\hat{\\beta_{j}}$ if fit on its own. The smallest possible value for VIF is 1, that indicates complete absence of collinearity. A rule of thumb rule is that if it exceeds 5 or 10 indicates a problematic amount of collinearity. \n",
    "\n",
    "The VIF for each variable can be computed using the formula\n",
    "\n",
    "$$VIF(\\hat{\\beta_{j}}) = \\dfrac{1}{1 - R^{2}_{X_{j}|X_{-j}}} $$\n",
    "\n",
    "Where $R^{2}_{X_{j}|X_{-j}}$ is the $R^{2}$ from a regression of $X_{j}$ onto all the other predictors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
